input {
 file {
    type => "json"
    # Logstash insists on absolute paths...
    path => "/opt/customer/neo/apps/eLoader/microservices/cms-service/logs/*.log.*"
    codec => json
  }

  file {
    codec => json
    type => "json"
    path => "/opt/customer/neo/apps/eLoader/microservices/dctm-export-service/logs/*.log.*"
  }
  file {
    codec => json
    type => "json"
    path => "/opt/customer/neo/apps/eLoader/microservices/dctm-importmetadata-service/logs/*.log.*"
  }

  file {
    codec => json
    type => "json"
    path => "/opt/customer/neo/apps/eLoader/microservices/eloader-eureka-server/logs/*.log.*"
  }
  file {
    codec => json
    type => "json"
    path => "/opt/customer/neo/apps/eLoader/microservices/eloader-config-server/logs/*.log.*"
  }
  file {
    codec => json
    type => "json"
    path => "/opt/customer/neo/apps/eLoader/microservices/eloader-consumer/logs/*.log.*"
  }
  file {
    codec => json
    type => "json"
    path => "/opt/customer/neo/apps/eLoader/microservices/eloader-microservice/logs/*.log.*"
  }
  file {
    codec => json
    type => "json"
    path => /opt/customer/neo/apps/eLoader/microservices/eloader-processing-service/logs/*.log.*"
  }
}

filter {
  #If log line contains tab character followed by 'at' then we will tag that entry as stacktrace
  if [message] =~ "\tat" {
    grok {
      match => ["message", "^(\tat)"]
      add_tag => ["stacktrace"]
    }
  }

  
  #Parsing out timestamps which are in timestamp field thanks to previous grok section
  date {
    match => [ "timestamp" , "yyyy-MM-dd HH:mm:ss.SSS" ]
  }
}

output {
  # Print each event to stdout, useful for debugging. Should be commented out in production.
  # Enabling 'rubydebug' codec on the stdout output will make logstash
  # pretty-print the entire event as something similar to a JSON representation.
  stdout {
    codec => rubydebug
  }

  # Sending properly parsed log events to elasticsearch
  elasticsearch {
    hosts => [ "10.99.18.152" ]
  }
}